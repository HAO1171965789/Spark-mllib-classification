{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**案例描述**\n",
    "\n",
    "本案例为《Spark大数据分析平台》课程第六章分类模型配套案例。数据来自手机APP\"Kalboard 360\"的学习管理系统（LMS）。Kalboard 360旨在利用尖端技术来提升学校K-12教育的教育水平。数据集由480个学生记录和16个特征组成。这些特征分为三大类：\n",
    "\n",
    "（1）性别和国籍等人口统计特征。\n",
    "\n",
    "（2）学历背景特征，如教育阶段，年级和隶属教室。\n",
    "\n",
    "（3）行为特征，如上课举手，访问资源，家长回答问卷调查，学校满意度等。\n",
    "\n",
    "该数据集的收集来自两个学期：第一学期收集了245个学生记录，第二学期收集了235个学生记录。最后学生依据其总成绩被分为三类：\n",
    "低：0-69、中：70-89、高：90-100。\n",
    "\n",
    "我们的任务是根据收集的数据，利用`pyspark.ml`库中的分类算法预测学生的成绩等级。`pyspark.ml`库对DataFrame进行操作，需要把数据转化为DataFrame。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据字段及说明：**\n",
    "\n",
    "| 特征                     \t| 说明                                                                                                      \t|\n",
    "|--------------------------\t|-----------------------------------------------------------------------------------------------------------\t|\n",
    "| gender                   \t| 学生性别（ 'Male' or 'Female’）                                                                           \t|\n",
    "| NationalITy              \t| 学生国籍                                                                                                  \t|\n",
    "| PlaceofBirth             \t| 学生的出生地                                                                                              \t|\n",
    "| StageID                  \t| 受教育水平（‘lowerlevel’,’MiddleSchool’,’HighSchool’）                                                    \t|\n",
    "| GradeID                  \t| 年级（‘G-01’, ‘G-02’, ‘G-03’,   ‘G-04’, ‘G-05’, ‘G-06’, ‘G-07’, ‘G-08’, ‘G-09’, ‘G-10’, ‘G-11’, ‘G-12 ‘） \t|\n",
    "| SectionID                \t| 隶属的教室（’A’,’B’,’C’）                                                                                 \t|\n",
    "| Topic                    \t| 课程名                                                                                                    \t|\n",
    "| Semester                 \t| 学校的学期（’ First’,’ Second’）                                                                          \t|\n",
    "| Relation                 \t| 监护学生的家长（’mom’,’father’）                                                                          \t|\n",
    "| raisedhands              \t| 学生在教室中举手次数（0-100）                                                                             \t|\n",
    "| VisITedResources         \t| 学生访问在线课程次数（0-100）                                                                             \t|\n",
    "| AnnouncementsView        \t| 学生检查新公告的次数（0-100）                                                                             \t|\n",
    "| Discussion               \t| 学生参加讨论组的次数（0-100）                                                                             \t|\n",
    "| ParentAnsweringSurvey    \t| 家长是否回答了学校提供的调查问卷（’Yes’,’No’）                                                            \t|\n",
    "| ParentschoolSatisfaction \t| 家长对学校的满意度（’Yes’,’No’）                                                                          \t|\n",
    "| StudentAbsenceDays       \t| 每个学生的缺勤天数（'above-7', 'under-7'）                                                                    \t|\n",
    "| Class                    \t| 根据学生的总成绩分为三个等级（低分：0-69，中等分数：70-89，高分：90-100）                              \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "[1. 读取数据及探索性分析](#1)<br>\n",
    "[2. 数据预处理](#2)<br>\n",
    "[3. LogisticRegression分析](#3)<br>\n",
    "[4. RandomForestClassifier分析](#4)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=1></div>\n",
    "\n",
    "# 1. 读取数据及探索性分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据量较少的情况下，可以考虑使用Pandas中的`read_csv`函数读取并查看数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'file:/home/spark/Spark/xAPI-Edu-Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "2      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "3      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "4      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pandas_data = pd.read_csv(path)\n",
    "print(pandas_data.shape)\n",
    "pandas_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出数据集共有480行数据，数据维度为17。\n",
    "\n",
    "接下来利用`dtypes`函数查找出哪些列中的数据不是数字。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID',\n",
       "       'SectionID', 'Topic', 'Semester', 'Relation', 'ParentAnsweringSurvey',\n",
       "       'ParentschoolSatisfaction', 'StudentAbsenceDays', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_columns = pandas_data.dtypes[pandas_data.dtypes == 'object'].index\n",
    "str_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在把数据转化为DataFrame之前，可以通过`textFile`函数把数据转化为RDD并查看数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender,NationalITy,PlaceofBirth,StageID,GradeID,SectionID,Topic,Semester,Relation,raisedhands,VisITedResources,AnnouncementsView,Discussion,ParentAnsweringSurvey,ParentschoolSatisfaction,StudentAbsenceDays,Class',\n",
       " 'M,venzuela,venzuela,HighSchool,G-10,A,IT,F,Mum,80,90,70,80,Yes,Good,Under-7,H',\n",
       " 'M,lebanon,lebanon,lowerlevel,G-02,B,French,S,Mum,40,51,20,33,No,Bad,Under-7,M',\n",
       " 'M,lebanon,lebanon,MiddleSchool,G-08,C,Spanish,S,Father,80,51,40,24,No,Good,Under-7,M',\n",
       " 'M,lebanon,lebanon,MiddleSchool,G-08,C,Spanish,S,Father,77,69,41,13,Yes,Good,Under-7,M']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile(path)\n",
    "data.top(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载数据并把数据转化为DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定数据集的`schema`：首先通过`types`函数指定标签及标签类型，然后通过`types.StructType`函数指定`schema`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "labels = [\n",
    "    ('gender', typ.StringType()),\n",
    "    ('NationalITy', typ.StringType()),\n",
    "    ('PlaceofBirth', typ.StringType()),\n",
    "    ('StageID', typ.StringType()),\n",
    "    ('GradeID', typ.StringType()),\n",
    "    ('SectionID', typ.StringType()),\n",
    "    ('Topic', typ.StringType()),\n",
    "    ('Semester', typ.StringType()),\n",
    "    ('Relation', typ.StringType()),\n",
    "    ('raisedhands', typ.IntegerType()),\n",
    "    ('VisITedResources', typ.IntegerType()),\n",
    "    ('AnnouncementsView', typ.IntegerType()),\n",
    "    ('Discussion', typ.IntegerType()),\n",
    "    ('ParentAnsweringSurvey', typ.StringType()),\n",
    "    ('ParentschoolSatisfaction', typ.StringType()),\n",
    "    ('StudentAbsenceDays', typ.StringType()),\n",
    "    ('Class', typ.StringType()),\n",
    "]\n",
    "\n",
    "schema = typ.StructType([\n",
    "    typ.StructField(e[0], e[1], False) for e in labels\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`spark.read.csv`函数中传参：`schema=schema`，读入数据并把数据转化为DataFrame格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------+----------+-------+---------+-----+--------+--------+-----------+----------------+-----------------+----------+---------------------+------------------------+------------------+-----+\n",
      "|gender|NationalITy|PlaceofBirth|   StageID|GradeID|SectionID|Topic|Semester|Relation|raisedhands|VisITedResources|AnnouncementsView|Discussion|ParentAnsweringSurvey|ParentschoolSatisfaction|StudentAbsenceDays|Class|\n",
      "+------+-----------+------------+----------+-------+---------+-----+--------+--------+-----------+----------------+-----------------+----------+---------------------+------------------------+------------------+-----+\n",
      "|     M|         KW|      KuwaIT|lowerlevel|   G-04|        A|   IT|       F|  Father|         15|              16|                2|        20|                  Yes|                    Good|           Under-7|    M|\n",
      "|     M|         KW|      KuwaIT|lowerlevel|   G-04|        A|   IT|       F|  Father|         20|              20|                3|        25|                  Yes|                    Good|           Under-7|    M|\n",
      "|     M|         KW|      KuwaIT|lowerlevel|   G-04|        A|   IT|       F|  Father|         10|               7|                0|        30|                   No|                     Bad|           Above-7|    L|\n",
      "+------+-----------+------------+----------+-------+---------+-----+--------+--------+-----------+----------------+-----------------+----------+---------------------+------------------------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('file:/home/spark/Spark/xAPI-Edu-Data.csv', \n",
    "                        header=True, \n",
    "                        schema=schema)\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`columns`函数查看DataFrame的所有列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', 'Topic', 'Semester', 'Relation', 'raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', 'StudentAbsenceDays', 'Class']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "cols = data.columns\n",
    "print(cols)\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`describe`函数对数据data进行描述性统计。描述性统计会展示关于数据集的基本信息：数据集中有多少非缺失的观测数据、列的平均值和标准偏差、还有最小值和最大值。data共有17列，在屏幕上不能很好的展示所有列，分两次展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+------------+----------+-------+---------+-------+--------+--------+----------------+\n",
      "|summary|gender|NationalITy|PlaceofBirth|   StageID|GradeID|SectionID|  Topic|Semester|Relation|     raisedhands|\n",
      "+-------+------+-----------+------------+----------+-------+---------+-------+--------+--------+----------------+\n",
      "|  count|   480|        480|         480|       480|    480|      480|    480|     480|     480|             480|\n",
      "|   mean|  null|       null|        null|      null|   null|     null|   null|    null|    null|          46.775|\n",
      "| stddev|  null|       null|        null|      null|   null|     null|   null|    null|    null|30.7792225827342|\n",
      "|    min|     F|      Egypt|       Egypt|HighSchool|   G-02|        A| Arabic|       F|  Father|               0|\n",
      "|    max|     M|   venzuela|    venzuela|lowerlevel|   G-12|        C|Spanish|       S|     Mum|             100|\n",
      "+-------+------+-----------+------------+----------+-------+---------+-------+--------+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe(cols[:10]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+---------------------+------------------------+------------------+-----+\n",
      "|summary|  VisITedResources| AnnouncementsView|        Discussion|ParentAnsweringSurvey|ParentschoolSatisfaction|StudentAbsenceDays|Class|\n",
      "+-------+------------------+------------------+------------------+---------------------+------------------------+------------------+-----+\n",
      "|  count|               480|               480|               480|                  480|                     480|               480|  480|\n",
      "|   mean|54.797916666666666|          37.91875| 43.28333333333333|                 null|                    null|              null| null|\n",
      "| stddev| 33.08000669966416|26.611244081903397|27.637735038376366|                 null|                    null|              null| null|\n",
      "|    min|                 0|                 0|                 1|                   No|                     Bad|           Above-7|    H|\n",
      "|    max|                99|                98|                99|                  Yes|                    Good|           Under-7|    M|\n",
      "+-------+------------------+------------------+------------------+---------------------+------------------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe(cols[10:]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上DataFrame中的`null`值是由于这些特征对应的数据是字符串，并不是数字，所以不能统计均值和标准偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更好地理解列，接下来利用`groupby`函数计算这些列值的使用频率,以`gender`和`Class`列为例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     F|  175|\n",
      "|     M|  305|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('gender').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到男生要比女生多，但数据集不存在类别分布极端不平衡的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|    M|  211|\n",
      "|    L|  127|\n",
      "|    H|  142|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('Class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到虽然成绩中等的学生要比其余两个成绩等级的学生多一些，但数据集不存在类别分布极端不平衡的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=2></div>\n",
    "\n",
    "# 2. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据集的基本信息中可以看到，有些特征的类型是字符型，需要在建模前做一些预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对特征的类型是字符型的列进行数值编码**\n",
    "\n",
    "统计模型只能对数值数据做操作，因此我们必须对非数值数据进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------------+----------+-----------+----------------+-----------------+------------+------------+--------------+----------+-------------+-------------+--------------------------+-----------------------------+-----------------------+----------+\n",
      "|raisedhands|VisITedResources|AnnouncementsView|Discussion|genderIndex|NationalITyIndex|PlaceofBirthIndex|StageIDIndex|GradeIDIndex|SectionIDIndex|TopicIndex|SemesterIndex|RelationIndex|ParentAnsweringSurveyIndex|ParentschoolSatisfactionIndex|StudentAbsenceDaysIndex|ClassIndex|\n",
      "+-----------+----------------+-----------------+----------+-----------+----------------+-----------------+------------+------------+--------------+----------+-------------+-------------+--------------------------+-----------------------------+-----------------------+----------+\n",
      "|         15|              16|                2|        20|        0.0|             0.0|              0.0|         1.0|         3.0|           0.0|       0.0|          0.0|          0.0|                       0.0|                          0.0|                    0.0|       0.0|\n",
      "|         20|              20|                3|        25|        0.0|             0.0|              0.0|         1.0|         3.0|           0.0|       0.0|          0.0|          0.0|                       0.0|                          0.0|                    0.0|       0.0|\n",
      "+-----------+----------------+-----------------+----------+-----------+----------------+-----------------+------------+------------+--------------+----------+-------------+-------------+--------------------------+-----------------------------+-----------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in str_columns:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=col+'Index')\n",
    "    data = indexer.fit(data).transform(data)\n",
    "for col in str_columns:\n",
    "    data = data.drop(col)\n",
    "data.show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用`columns`函数得出数值编码后数据data的所有列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion', 'genderIndex', 'NationalITyIndex', 'PlaceofBirthIndex', 'StageIDIndex', 'GradeIDIndex', 'SectionIDIndex', 'TopicIndex', 'SemesterIndex', 'RelationIndex', 'ParentAnsweringSurveyIndex', 'ParentschoolSatisfactionIndex', 'StudentAbsenceDaysIndex', 'ClassIndex']\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为方便后续建立模型，需要对除去目标特征之外的无序分类特征进行独热编码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "selected_features = columns[4:-1]\n",
    "encoder = OneHotEncoderEstimator(inputCols=selected_features,\n",
    "                             outputCols=[i + 'vec' for i in selected_features])\n",
    "data_encodered = encoder.fit(data).transform(data)\n",
    "# encoder_features = encoder.getOutputCols()\n",
    "# # new_labels = data_selected.columns\n",
    "# features = data_features + encoder_features\n",
    "# data_encodered\n",
    "for col in selected_features:\n",
    "    data_encodered = data_encodered.drop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------------+----------+----------+---------------+-------------------+---------------+--------------------+--------------+----------------+-----------------------------+-----------------+--------------------------------+--------------------------+----------------+--------------+\n",
      "|raisedhands|VisITedResources|AnnouncementsView|Discussion|ClassIndex|StageIDIndexvec|NationalITyIndexvec|GradeIDIndexvec|PlaceofBirthIndexvec| TopicIndexvec|RelationIndexvec|ParentAnsweringSurveyIndexvec|SectionIDIndexvec|ParentschoolSatisfactionIndexvec|StudentAbsenceDaysIndexvec|SemesterIndexvec|genderIndexvec|\n",
      "+-----------+----------------+-----------------+----------+----------+---------------+-------------------+---------------+--------------------+--------------+----------------+-----------------------------+-----------------+--------------------------------+--------------------------+----------------+--------------+\n",
      "|         15|              16|                2|        20|       0.0|  (2,[1],[1.0])|     (13,[0],[1.0])|  (9,[3],[1.0])|      (13,[0],[1.0])|(11,[0],[1.0])|   (1,[0],[1.0])|                (1,[0],[1.0])|    (2,[0],[1.0])|                   (1,[0],[1.0])|             (1,[0],[1.0])|   (1,[0],[1.0])| (1,[0],[1.0])|\n",
      "|         20|              20|                3|        25|       0.0|  (2,[1],[1.0])|     (13,[0],[1.0])|  (9,[3],[1.0])|      (13,[0],[1.0])|(11,[0],[1.0])|   (1,[0],[1.0])|                (1,[0],[1.0])|    (2,[0],[1.0])|                   (1,[0],[1.0])|             (1,[0],[1.0])|   (1,[0],[1.0])| (1,[0],[1.0])|\n",
      "+-----------+----------------+-----------------+----------+----------+---------------+-------------------+---------------+--------------------+--------------+----------------+-----------------------------+-----------------+--------------------------------+--------------------------+----------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_encodered.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=3></div>\n",
    "\n",
    "# 3. LogisticRegression分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用`VectorAssembler`方法整合所有特征**\n",
    "\n",
    "创建一个单一的列，将所有特征整合在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodered_columns = data_encodered.columns\n",
    "encodered_columns.remove('ClassIndex')\n",
    "\n",
    "import pyspark.ml.feature as ft\n",
    "featuresCreator = ft.VectorAssembler(\n",
    "    inputCols=encodered_columns, \n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建`LogisticRegression`评估器**\n",
    "\n",
    "针对本数据集，我们先用逻辑回归进行拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic = LogisticRegression(\n",
    "    maxIter=10, \n",
    "    regParam=0.1, \n",
    "    labelCol='ClassIndex')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建管道并拟合模型**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline1 = Pipeline(stages=[\n",
    "        featuresCreator, \n",
    "        logistic\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_encodered \\\n",
    "    .randomSplit([0.7, 0.3], seed=1)\n",
    "model = pipeline1.fit(train)\n",
    "test_model = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(raisedhands=0, VisITedResources=4, AnnouncementsView=8, Discussion=30, ClassIndex=2.0, StageIDIndexvec=SparseVector(2, {1: 1.0}), NationalITyIndexvec=SparseVector(13, {0: 1.0}), GradeIDIndexvec=SparseVector(9, {0: 1.0}), PlaceofBirthIndexvec=SparseVector(13, {0: 1.0}), TopicIndexvec=SparseVector(11, {0: 1.0}), RelationIndexvec=SparseVector(1, {}), ParentAnsweringSurveyIndexvec=SparseVector(1, {}), SectionIDIndexvec=SparseVector(2, {}), ParentschoolSatisfactionIndexvec=SparseVector(1, {}), StudentAbsenceDaysIndexvec=SparseVector(1, {}), SemesterIndexvec=SparseVector(1, {0: 1.0}), genderIndexvec=SparseVector(1, {0: 1.0}), features=SparseVector(60, {1: 4.0, 2: 8.0, 3: 30.0, 5: 1.0, 6: 1.0, 19: 1.0, 28: 1.0, 41: 1.0, 58: 1.0, 59: 1.0}), rawPrediction=DenseVector([-0.2687, -1.2538, 1.5225]), probability=DenseVector([0.1357, 0.0507, 0.8137]), prediction=2.0),\n",
       " Row(raisedhands=1, VisITedResources=7, AnnouncementsView=6, Discussion=10, ClassIndex=2.0, StageIDIndexvec=SparseVector(2, {1: 1.0}), NationalITyIndexvec=SparseVector(13, {0: 1.0}), GradeIDIndexvec=SparseVector(9, {0: 1.0}), PlaceofBirthIndexvec=SparseVector(13, {0: 1.0}), TopicIndexvec=SparseVector(11, {0: 1.0}), RelationIndexvec=SparseVector(1, {0: 1.0}), ParentAnsweringSurveyIndexvec=SparseVector(1, {}), SectionIDIndexvec=SparseVector(2, {1: 1.0}), ParentschoolSatisfactionIndexvec=SparseVector(1, {}), StudentAbsenceDaysIndexvec=SparseVector(1, {}), SemesterIndexvec=SparseVector(1, {0: 1.0}), genderIndexvec=SparseVector(1, {0: 1.0}), features=SparseVector(60, {0: 1.0, 1: 7.0, 2: 6.0, 3: 10.0, 5: 1.0, 6: 1.0, 19: 1.0, 28: 1.0, 41: 1.0, 52: 1.0, 55: 1.0, 58: 1.0, 59: 1.0}), rawPrediction=DenseVector([-0.0001, -2.25, 2.2501]), probability=DenseVector([0.0944, 0.0099, 0.8957]), prediction=2.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型性能评估**\n",
    "\n",
    "本数据集目标类别为三个，属于多分类问题。调用`MulticlassClassificationEvaluator`类进行模型评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_Accuracy:0.647\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='ClassIndex')\n",
    "print('LR_Accuracy:{0:.3f}'\\\n",
    "      .format(evaluator.evaluate(test_model, {evaluator.metricName: \"accuracy\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参数调优**\n",
    "\n",
    "使用逻辑回归后模型的精度不是特别理想，考虑使用网格搜索进行参数调优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入tuning包\n",
    "import pyspark.ml.tuning as tune\n",
    "# 指定模型\n",
    "logistic = LogisticRegression(labelCol='ClassIndex')\n",
    "# 指定要循环遍历的参数列表\n",
    "grid = tune.ParamGridBuilder().addGrid(logistic.maxIter, [2,10,30,50]).addGrid(logistic.regParam,[0.01,0.05,0.1,0.15]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_gd_Accuracy:0.698\n"
     ]
    }
   ],
   "source": [
    "# 指定评估模型的方法\n",
    "evaluator2 = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='ClassIndex')\n",
    "# 使用CrossValidator需要评估器、estimatorParamMaps和evaluator。该模型循环遍历值的网格，评估各个模型，并使用evaluator比较其性能\n",
    "cv = tune.CrossValidator(estimator=logistic,estimatorParamMaps=grid,evaluator=evaluator2)\n",
    "# 创建一个管道用于转化数据\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline2 = Pipeline(stages=[\n",
    "        featuresCreator, \n",
    "    ])\n",
    "data_transformer = pipeline2.fit(train)\n",
    "# 寻找模型的最佳参数组合\n",
    "cvModel2 = cv.fit(data_transformer.transform(train))\n",
    "test_model2 = cvModel2.transform(data_transformer.transform(test))\n",
    "\n",
    "print('LR_gd_Accuracy:{0:.3f}'\\\n",
    "      .format(evaluator2.evaluate(test_model2, {evaluator2.metricName: \"accuracy\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=4></div>\n",
    "\n",
    "# 4. RandomForestClassifier分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用逻辑回归进行分类的效果不是很理想，考虑使用随机森林对数据集进行分类。\n",
    "\n",
    "**创建`RandomForestClassifier`评估器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"ClassIndex\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建管道**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featuresCreator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e6c5997883a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m pipeline = Pipeline(stages=[\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfeaturesCreator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'featuresCreator' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "        featuresCreator, \n",
    "        rf\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**拟合模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_encodered \\\n",
    "    .randomSplit([0.7, 0.3], seed=1)\n",
    "model = pipeline.fit(train)\n",
    "test_model = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(raisedhands=0, VisITedResources=4, AnnouncementsView=8, Discussion=30, ClassIndex=2.0, StageIDIndexvec=SparseVector(2, {1: 1.0}), NationalITyIndexvec=SparseVector(13, {0: 1.0}), GradeIDIndexvec=SparseVector(9, {0: 1.0}), PlaceofBirthIndexvec=SparseVector(13, {0: 1.0}), TopicIndexvec=SparseVector(11, {0: 1.0}), RelationIndexvec=SparseVector(1, {}), ParentAnsweringSurveyIndexvec=SparseVector(1, {}), SectionIDIndexvec=SparseVector(2, {}), ParentschoolSatisfactionIndexvec=SparseVector(1, {}), StudentAbsenceDaysIndexvec=SparseVector(1, {}), SemesterIndexvec=SparseVector(1, {0: 1.0}), genderIndexvec=SparseVector(1, {0: 1.0}), features=SparseVector(60, {1: 4.0, 2: 8.0, 3: 30.0, 5: 1.0, 6: 1.0, 19: 1.0, 28: 1.0, 41: 1.0, 58: 1.0, 59: 1.0}), rawPrediction=DenseVector([1.168, 0.0781, 8.7539]), probability=DenseVector([0.1168, 0.0078, 0.8754]), prediction=2.0),\n",
       " Row(raisedhands=1, VisITedResources=7, AnnouncementsView=6, Discussion=10, ClassIndex=2.0, StageIDIndexvec=SparseVector(2, {1: 1.0}), NationalITyIndexvec=SparseVector(13, {0: 1.0}), GradeIDIndexvec=SparseVector(9, {0: 1.0}), PlaceofBirthIndexvec=SparseVector(13, {0: 1.0}), TopicIndexvec=SparseVector(11, {0: 1.0}), RelationIndexvec=SparseVector(1, {0: 1.0}), ParentAnsweringSurveyIndexvec=SparseVector(1, {}), SectionIDIndexvec=SparseVector(2, {1: 1.0}), ParentschoolSatisfactionIndexvec=SparseVector(1, {}), StudentAbsenceDaysIndexvec=SparseVector(1, {}), SemesterIndexvec=SparseVector(1, {0: 1.0}), genderIndexvec=SparseVector(1, {0: 1.0}), features=SparseVector(60, {0: 1.0, 1: 7.0, 2: 6.0, 3: 10.0, 5: 1.0, 6: 1.0, 19: 1.0, 28: 1.0, 41: 1.0, 52: 1.0, 55: 1.0, 58: 1.0, 59: 1.0}), rawPrediction=DenseVector([1.168, 0.0781, 8.7539]), probability=DenseVector([0.1168, 0.0078, 0.8754]), prediction=2.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**评估模型性能**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_Accuracy:0.662\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='ClassIndex')\n",
    "\n",
    "print('RF_Accuracy:{0:.3f}'\\\n",
    "      .format(evaluator.evaluate(test_model, {evaluator.metricName: \"accuracy\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参数调优**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"ClassIndex\", featuresCol=\"features\")\n",
    "grid = tune.ParamGridBuilder().addGrid(rf.numTrees, [4,8,10,12,14,16]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_gd_Accuracy:0.71\n"
     ]
    }
   ],
   "source": [
    "evaluator2 = MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='ClassIndex')\n",
    "cv = tune.CrossValidator(estimator=rf,estimatorParamMaps=grid,evaluator=evaluator2)\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline2 = Pipeline(stages=[\n",
    "        featuresCreator, \n",
    "    ])\n",
    "data_transformer = pipeline2.fit(train)\n",
    "# 寻找模型的最佳参数组合\n",
    "cvModel2 = cv.fit(data_transformer.transform(train))\n",
    "test_model2 = cvModel2.transform(data_transformer.transform(test))\n",
    "print('RF_gd_Accuracy:{0:.2f}'\\\n",
    "      .format(evaluator2.evaluate(test_model2, {evaluator2.metricName: \"accuracy\"})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
